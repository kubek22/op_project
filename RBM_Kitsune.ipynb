{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhQUQP5uo9DJ",
    "outputId": "93e276d6-5801-49a2-a3c9-756da8e99250",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:01:54.039112Z",
     "start_time": "2025-06-06T20:01:54.036834Z"
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# DATA_DIR = '/content/drive/MyDrive/kitsune+network+attack+dataset.zip'\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# import zipfile\n",
    "# import os\n",
    "# \n",
    "# extract_dir = '/content/kitsune'\n",
    "# os.makedirs(extract_dir, exist_ok=True)\n",
    "# \n",
    "# with zipfile.ZipFile(DATA_DIR, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(extract_dir)"
   ],
   "metadata": {
    "id": "xsa3kUEdq74Y",
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-06T20:01:54.049029Z",
     "start_time": "2025-06-06T20:01:54.045318Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T20:01:56.636665Z",
     "start_time": "2025-06-06T20:01:54.051239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_rbm import RBM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "from softmax import Net, train\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "extract_dir = 'content/kitsune'\n",
    "attack_dirs = sorted([d for d in os.listdir(extract_dir) if os.path.isdir(os.path.join(extract_dir, d))])\n",
    "print(\"Available attack directories:\")\n",
    "for attack in attack_dirs:\n",
    "    print(\" -\", attack)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvR4ouGmJUHZ",
    "outputId": "9bf10ee1-b298-4b8f-ac1f-64de23759056",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:01:56.693684Z",
     "start_time": "2025-06-06T20:01:56.691383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attack directories:\n",
      " - active_wiretap\n",
      " - arp_mitm\n",
      " - fuzzing\n",
      " - mirai\n",
      " - os_scan\n",
      " - ssdp_flood\n",
      " - ssl_renegotiation\n",
      " - syn_dos\n",
      " - video_injection\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "k_sample = 0.1\n",
    "\n",
    "attack_mapping = {\n",
    "    'os_scan'            : 'OS Scan',\n",
    "    'fuzzing'            : 'Fuzzing',\n",
    "    'video_injection'    : 'Video Injection',\n",
    "    'arp_mitm'           : 'ARP MitM',\n",
    "    'active_wiretap'     : 'Active Wiretap',\n",
    "    'ssdp_flood'         : 'SSDP Flood',\n",
    "    'syn_dos'            : 'SYN DoS',\n",
    "    'ssl_renegotiation'  : 'SSL Renegotiation',\n",
    "    'mirai'              : 'Mirai'\n",
    "}\n",
    "\n",
    "# features_dfs = {}\n",
    "# labels_dfs   = {}\n",
    "errors       = []\n",
    "\n",
    "\n",
    "feature_list = []\n",
    "label_list   = []\n",
    "\n",
    "# ─── 4) Loop over each directory, build exact filenames, and load ────────────────\n",
    "\n",
    "for folder in attack_dirs:\n",
    "    if folder not in attack_mapping:\n",
    "        errors.append(f\"→ No mapping found for folder: '{folder}'\")\n",
    "        continue\n",
    "\n",
    "    base_name   = attack_mapping[folder]          # e.g. \"Active Wiretap\"\n",
    "    attack_path = os.path.join(extract_dir, folder)\n",
    "\n",
    "    # Build the expected .csv.gz paths\n",
    "    features_path = os.path.join(attack_path, f\"{base_name}_dataset.csv.gz\")\n",
    "    labels_path   = os.path.join(attack_path, f\"{base_name}_labels.csv.gz\")\n",
    "\n",
    "    try:\n",
    "        # --- 4a) Load features ---\n",
    "        print(f\"Loading features for '{folder}' from:\\n  {features_path}\")\n",
    "        df_feat = pd.read_csv(features_path, compression='gzip', header=None)\n",
    "        print(f\"  → Features shape: {df_feat.shape}\")\n",
    "\n",
    "\n",
    "        if folder == 'mirai':\n",
    "            # Mirai labels file has only one column (no index column)\n",
    "            print(f\"Loading MIRAI labels (single‐column) from:\\n  {labels_path}\")\n",
    "            df_lbl = pd.read_csv(\n",
    "                labels_path,\n",
    "                compression='gzip',\n",
    "                header=None,     # assume first line is a header like \"label\", drop it\n",
    "            )\n",
    "        else:\n",
    "            # --- 4b) Load labels (parse index,col properly) ---\n",
    "            print(f\"Loading labels for '{folder}' from:\\n  {labels_path}\")\n",
    "            df_lbl = pd.read_csv(\n",
    "              labels_path,\n",
    "              compression='gzip',\n",
    "              sep=',',           # split “index,label”\n",
    "              header=0,          # treat first line (e.g. \"0,x\") as header\n",
    "              index_col=0,       # drop the index‐column\n",
    "              names=['index','label']\n",
    "            )\n",
    "            print(f\"  → Labels shape:   {df_lbl.shape}\")\n",
    "            df_lbl = df_lbl['label']\n",
    "\n",
    "        # 4c) Verify row counts match\n",
    "        if df_feat.shape[0] != df_lbl.shape[0]:\n",
    "            msg = (\n",
    "                f\"features {df_feat.shape[0]} vs labels {df_lbl.shape[0]}\"\n",
    "            )\n",
    "            errors.append(msg)\n",
    "        else:\n",
    "            print(f\"Row counts match ({df_feat.shape[0]} packets)\\n\")\n",
    "\n",
    "\n",
    "        # sample k_sample from entire dataset (stratified on y)\n",
    "        # _, df_feat_sample, _, df_lbl_sample = train_test_split(\n",
    "        #             df_feat,\n",
    "        #             df_lbl,\n",
    "        #             test_size=k_sample,\n",
    "        #             random_state=0,\n",
    "        #             stratify=df_lbl\n",
    "        #         )\n",
    "        \n",
    "        # loading full dataset\n",
    "        df_feat_sample = df_feat\n",
    "        df_lbl_sample = df_lbl\n",
    "\n",
    "        # del df_feat, df_lbl, _\n",
    "        # Reset indices for consistency\n",
    "        df_feat_sample = df_feat_sample.reset_index(drop=True)\n",
    "        df_lbl_sample  = df_lbl_sample.reset_index(drop=True)\n",
    "\n",
    "        feature_list.append(df_feat_sample)\n",
    "        label_list.append(df_lbl_sample)\n",
    "\n",
    "        # del df_feat_sample, df_lbl_sample\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Failed to load '{folder}': {e}\\n\")\n",
    "\n",
    "# ─── 5) Summary ─────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"────────────────────────────────────────\")\n",
    "print(f\"Successfully loaded {len(feature_list)} attack datasets.\")\n",
    "if errors:\n",
    "    print(\"\\nSome folders could not be loaded or had mismatches:\")\n",
    "    for e in errors:\n",
    "        print(\" \", e)\n",
    "else:\n",
    "    print(\"No errors detected. All row counts match.\\n\")\n",
    "\n",
    "# Now you can access, for example:\n",
    "#   features_dfs['active_wiretap']   → pandas DataFrame of shape (N, 115)\n",
    "#   labels_dfs  ['active_wiretap']   → pandas Series of length N\n",
    "\n",
    "# Example: display the first 3 rows of “active_wiretap” features & labels\n",
    "# demo_folder = 'active_wiretap'\n",
    "# if demo_folder in features_dfs:\n",
    "#     print(f\"\\nExample: first 3 rows of {demo_folder} features:\")\n",
    "#     display(features_dfs[demo_folder].head(3))\n",
    "#     print(f\"\\nExample: first 10 labels of {demo_folder}:\")\n",
    "#     display(labels_dfs[demo_folder].head(10))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P3US3BqUyZbn",
    "outputId": "de7ee382-a3c8-494c-dd2d-bd02374c04ed",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:07:32.534399Z",
     "start_time": "2025-06-06T20:01:56.774172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features for 'active_wiretap' from:\n",
      "  content/kitsune\\active_wiretap\\Active Wiretap_dataset.csv.gz\n",
      "  → Features shape: (2278689, 115)\n",
      "Loading labels for 'active_wiretap' from:\n",
      "  content/kitsune\\active_wiretap\\Active Wiretap_labels.csv.gz\n",
      "  → Labels shape:   (2278689, 1)\n",
      "Row counts match (2278689 packets)\n",
      "\n",
      "Loading features for 'arp_mitm' from:\n",
      "  content/kitsune\\arp_mitm\\ARP MitM_dataset.csv.gz\n",
      "  → Features shape: (2504267, 115)\n",
      "Loading labels for 'arp_mitm' from:\n",
      "  content/kitsune\\arp_mitm\\ARP MitM_labels.csv.gz\n",
      "  → Labels shape:   (2504267, 1)\n",
      "Row counts match (2504267 packets)\n",
      "\n",
      "Loading features for 'fuzzing' from:\n",
      "  content/kitsune\\fuzzing\\Fuzzing_dataset.csv.gz\n",
      "  → Features shape: (2244139, 115)\n",
      "Loading labels for 'fuzzing' from:\n",
      "  content/kitsune\\fuzzing\\Fuzzing_labels.csv.gz\n",
      "  → Labels shape:   (2244139, 1)\n",
      "Row counts match (2244139 packets)\n",
      "\n",
      "Loading features for 'mirai' from:\n",
      "  content/kitsune\\mirai\\Mirai_dataset.csv.gz\n",
      "  → Features shape: (764137, 116)\n",
      "Loading MIRAI labels (single‐column) from:\n",
      "  content/kitsune\\mirai\\Mirai_labels.csv.gz\n",
      "Row counts match (764137 packets)\n",
      "\n",
      "Loading features for 'os_scan' from:\n",
      "  content/kitsune\\os_scan\\OS Scan_dataset.csv.gz\n",
      "  → Features shape: (1697851, 115)\n",
      "Loading labels for 'os_scan' from:\n",
      "  content/kitsune\\os_scan\\OS Scan_labels.csv.gz\n",
      "  → Labels shape:   (1697851, 1)\n",
      "Row counts match (1697851 packets)\n",
      "\n",
      "Loading features for 'ssdp_flood' from:\n",
      "  content/kitsune\\ssdp_flood\\SSDP Flood_dataset.csv.gz\n",
      "  → Features shape: (4077266, 115)\n",
      "Loading labels for 'ssdp_flood' from:\n",
      "  content/kitsune\\ssdp_flood\\SSDP Flood_labels.csv.gz\n",
      "  → Labels shape:   (4077266, 1)\n",
      "Row counts match (4077266 packets)\n",
      "\n",
      "Loading features for 'ssl_renegotiation' from:\n",
      "  content/kitsune\\ssl_renegotiation\\SSL Renegotiation_dataset.csv.gz\n",
      "  → Features shape: (2207571, 115)\n",
      "Loading labels for 'ssl_renegotiation' from:\n",
      "  content/kitsune\\ssl_renegotiation\\SSL Renegotiation_labels.csv.gz\n",
      "  → Labels shape:   (2207571, 1)\n",
      "Row counts match (2207571 packets)\n",
      "\n",
      "Loading features for 'syn_dos' from:\n",
      "  content/kitsune\\syn_dos\\SYN DoS_dataset.csv.gz\n",
      "  → Features shape: (2771276, 115)\n",
      "Loading labels for 'syn_dos' from:\n",
      "  content/kitsune\\syn_dos\\SYN DoS_labels.csv.gz\n",
      "  → Labels shape:   (2771276, 1)\n",
      "Row counts match (2771276 packets)\n",
      "\n",
      "Loading features for 'video_injection' from:\n",
      "  content/kitsune\\video_injection\\Video Injection_dataset.csv.gz\n",
      "  → Features shape: (2472401, 115)\n",
      "Loading labels for 'video_injection' from:\n",
      "  content/kitsune\\video_injection\\Video Injection_labels.csv.gz\n",
      "  → Labels shape:   (2472401, 1)\n",
      "Row counts match (2472401 packets)\n",
      "\n",
      "────────────────────────────────────────\n",
      "Successfully loaded 9 attack datasets.\n",
      "No errors detected. All row counts match.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(feature_list))\n",
    "print(len(label_list))\n",
    "print(feature_list[0].shape)\n",
    "for df in feature_list:\n",
    "    print(df.shape)\n",
    "    # print(df.head())\n",
    "    \n",
    "feature_list[3] = feature_list[3].iloc[:, 1:]"
   ],
   "metadata": {
    "id": "O2bQGcVJkAhs",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:07:32.929942Z",
     "start_time": "2025-06-06T20:07:32.767148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "(2278689, 115)\n",
      "(2278689, 115)\n",
      "(2504267, 115)\n",
      "(2244139, 115)\n",
      "(764137, 116)\n",
      "(1697851, 115)\n",
      "(4077266, 115)\n",
      "(2207571, 115)\n",
      "(2771276, 115)\n",
      "(2472401, 115)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# feature_list[3] = feature_list[3].iloc[:, 1:]\n",
    "# label_list   = []\n",
    "# \n",
    "# for folder in list(features_dfs.keys()):\n",
    "#     df_feat = features_dfs.pop(folder)\n",
    "#     df_lbl  = labels_dfs.pop(folder)\n",
    "# \n",
    "#     if folder == 'mirai':\n",
    "#         df_feat = df_feat.iloc[:, 1:]\n",
    "# \n",
    "#     feature_list.append(df_feat)\n",
    "#     label_list.append(df_lbl)"
   ],
   "metadata": {
    "id": "OzCD95qiBehs",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:07:33.211651Z",
     "start_time": "2025-06-06T20:07:33.207606Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# merging data\n",
    "X = pd.concat(feature_list, ignore_index=True)\n",
    "y = pd.concat(label_list, ignore_index=True)\n",
    "\n",
    "del feature_list, label_list\n",
    "\n",
    "nan_counts = X.isna().sum(axis=1)\n",
    "print(nan_counts.value_counts().sort_index())\n",
    "\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.fillna(X.mean())\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ],
   "metadata": {
    "id": "-8xuJnTZJYkl",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:09:17.963652Z",
     "start_time": "2025-06-06T20:07:33.478062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    21017597\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T20:09:19.045983Z",
     "start_time": "2025-06-06T20:09:19.025354Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21017597, 116)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# # free memory\n",
    "# for name in dir():\n",
    "#     if name not in ['X', 'y'] and not name.startswith('_'):\n",
    "#         del globals()[name]\n",
    "# import gc\n",
    "# gc.collect()"
   ],
   "metadata": {
    "id": "0QxgVWUWJZrM",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:09:19.268244Z",
     "start_time": "2025-06-06T20:09:19.264045Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "X, X_val, y, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X.shape}\")\n",
    "print(f\"X_val   shape: {X_val.shape}\")\n",
    "print(f\"y_train shape: {y.shape}\")\n",
    "print(f\"y_val   shape: {y_val.shape}\")"
   ],
   "metadata": {
    "id": "fErFu3ztBSw8",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:10:42.101291Z",
     "start_time": "2025-06-06T20:09:19.705558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (16814077, 116)\n",
      "X_val   shape: (4203520, 116)\n",
      "y_train shape: (16814077, 1)\n",
      "y_val   shape: (4203520, 1)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "standard_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_stand = standard_scaler.fit_transform(X)\n",
    "X_norm = minmax_scaler.fit_transform(X_stand)\n",
    "\n",
    "X_val_stand = standard_scaler.transform(X_val)\n",
    "X_val_norm = minmax_scaler.transform(X_val_stand)\n",
    "\n",
    "del X, X_val, X_stand, X_val_stand"
   ],
   "metadata": {
    "id": "kYmdwUiDH6Ps",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:11:16.617526Z",
     "start_time": "2025-06-06T20:10:42.481370Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "X_train_tensor = torch.tensor(X_norm, dtype=torch.double)\n",
    "Y_train_tensor = torch.tensor(np.array(y), dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val_norm, dtype=torch.double)\n",
    "Y_val_tensor = torch.tensor(np.array(y_val), dtype=torch.long)\n",
    "\n",
    "del X_norm, X_val_norm"
   ],
   "metadata": {
    "id": "5HtLRwe3RN5V",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:11:18.506931Z",
     "start_time": "2025-06-06T20:11:16.917578Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "id": "5XKHygLERQcL",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:29:25.298617Z",
     "start_time": "2025-06-06T20:11:18.775440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "input_size = X_train_tensor.shape[1] # 78 # 116\n",
    "rbm = RBM(input_size, 50, device)\n",
    "rbm = rbm.to(device)\n",
    "print(datetime.datetime.now())\n",
    "print(\"Training RBM using the original RBM code...\")\n",
    "rbm.fit(X_train_tensor, iterations=20, learning_rate=0.01, cd_n=1, batch_size=4096, verbose=True)\n",
    "print(\"RBM training complete.\")\n",
    "print(datetime.datetime.now())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-06 22:11:18.981303\n",
      "Training RBM using the original RBM code...\n",
      "Iteration: 1 of 20\n",
      "Iteration: 2 of 20\n",
      "Iteration: 3 of 20\n",
      "Iteration: 4 of 20\n",
      "Iteration: 5 of 20\n",
      "Iteration: 6 of 20\n",
      "Iteration: 7 of 20\n",
      "Iteration: 8 of 20\n",
      "Iteration: 9 of 20\n",
      "Iteration: 10 of 20\n",
      "Iteration: 11 of 20\n",
      "Iteration: 12 of 20\n",
      "Iteration: 13 of 20\n",
      "Iteration: 14 of 20\n",
      "Iteration: 15 of 20\n",
      "Iteration: 16 of 20\n",
      "Iteration: 17 of 20\n",
      "Iteration: 18 of 20\n",
      "Iteration: 19 of 20\n",
      "Iteration: 20 of 20\n",
      "RBM training complete.\n",
      "2025-06-06 22:29:25.290528\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T20:47:34.083990Z",
     "start_time": "2025-06-06T20:47:06.885500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "H_train_tensor = torch.tensor(rbm.draw_hidden(X_train_tensor), dtype=torch.float)\n",
    "H_val_tensor = torch.tensor(rbm.draw_hidden(X_val_tensor), dtype=torch.float)\n",
    "\n",
    "dataset_Train = TensorDataset(H_train_tensor.cpu(), Y_train_tensor.squeeze().cpu())\n",
    "dataset_val = TensorDataset(H_val_tensor.cpu(), Y_val_tensor.squeeze().cpu())\n",
    "\n",
    "batch_size = 4096\n",
    "loader_train = DataLoader(dataset_Train, batch_size=batch_size, shuffle=True)\n",
    "loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_26656\\56768158.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  H_train_tensor = torch.tensor(rbm.draw_hidden(X_train_tensor), dtype=torch.float)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_26656\\56768158.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  H_val_tensor = torch.tensor(rbm.draw_hidden(X_val_tensor), dtype=torch.float)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T20:47:45.288483Z",
     "start_time": "2025-06-06T20:47:44.227210Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T21:09:46.795212Z",
     "start_time": "2025-06-06T20:47:49.594116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Net(50, 2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# optimizer = optim.SGD(model.parameters())\n",
    "# optimizer = optim.RMSprop(model.parameters())\n",
    "history_Adam = train(10, model, loader_train, loader_val, optimizer, criterion, device, model_path='test')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, training loss: 7.83365356800507e-05, training accuracy: 86.18891777407704\n",
      "epoch: 1, validation loss: 7.534809038354975e-05, validation accuracy: 86.2932256775274\n",
      "model saved\n",
      "\n",
      "epoch: 2, training loss: 7.523838525069918e-05, training accuracy: 86.29053500825529\n",
      "epoch: 2, validation loss: 7.52192468469765e-05, validation accuracy: 86.29305915042632\n",
      "model saved\n",
      "\n",
      "epoch: 3, training loss: 7.520389745537175e-05, training accuracy: 86.28116190974978\n",
      "epoch: 3, validation loss: 7.525875203903588e-05, validation accuracy: 86.30638131851401\n",
      "\n",
      "epoch: 4, training loss: 7.520255787955125e-05, training accuracy: 86.27713552162274\n",
      "epoch: 4, validation loss: 7.522480830892775e-05, validation accuracy: 86.28830123325213\n",
      "\n",
      "epoch: 5, training loss: 7.520194098103831e-05, training accuracy: 86.27535724976161\n",
      "epoch: 5, validation loss: 7.521662999786227e-05, validation accuracy: 86.28920523751522\n",
      "model saved\n",
      "\n",
      "epoch: 6, training loss: 7.520046325593899e-05, training accuracy: 86.27561893525288\n",
      "epoch: 6, validation loss: 7.521478254625962e-05, validation accuracy: 86.281140567905\n",
      "model saved\n",
      "\n",
      "epoch: 7, training loss: 7.520054066292502e-05, training accuracy: 86.27515503824563\n",
      "epoch: 7, validation loss: 7.522165193647855e-05, validation accuracy: 86.28223488885506\n",
      "\n",
      "epoch: 8, training loss: 7.520084612026464e-05, training accuracy: 86.27519072263081\n",
      "epoch: 8, validation loss: 7.521236514168974e-05, validation accuracy: 86.27759591961023\n",
      "model saved\n",
      "\n",
      "epoch: 9, training loss: 7.520307212234864e-05, training accuracy: 86.2756843566257\n",
      "epoch: 9, validation loss: 7.522340195228535e-05, validation accuracy: 86.2896334500609\n",
      "\n",
      "epoch: 10, training loss: 7.520071483750588e-05, training accuracy: 86.27400719052255\n",
      "epoch: 10, validation loss: 7.52194107571973e-05, validation accuracy: 86.28125951583435\n",
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
